# Практическое задание (1)


1.  Была создана валидационная выборка – путем случайного выбора изображений из обучающей выборки:

    train.size = 323    
    val.size = 55   

2.	Из-за небольшого размера обучающей выборки было решено реализовать аугментацию данных – исходные изображения были отражены по горизонтали, вертикали, были повернуты. В результате таких преобразований, обучающая выборка была увеличена в 6 раз: 

    323 -> 1938

3.	Было решено использовать сеть с двумя промежуточными слоями, имеющими функцию активации ReLU, и линейным последним слоем. Функцией потерь была выбрана Cross Entropy, метрикой являлось Accuracy. В качестве оптимизатора было решено выбрать Adam:

    L1: 30*32 -> 256    
    R1: ReLU    
    L2: 256 -> 64   
    R2: ReLU    
    L3: 64 -> 2   

    Optimizer: Adam   
    Loss: CrossEntrapy    
    Accuracy = 1/n* ∑_(i=1)^n▒〖(〖pred〗_i==y_i)〗   

4.	Выполнено обучение сети с временем, равным 100 эпохам.
По результатам функции потерь было замечено, что после 40 эпох начинается переобучение.

5.	После этого было выполнено обучение итоговой версии нейронной сети с 40 эпохами, были получены следующие значения функции потерь и метрики:

    Loss: 0.0973
    Acc: 0.9818
